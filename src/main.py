import typer
import pandas as pd
from pathlib import Path
from datetime import datetime
import sys
import os
from dotenv import load_dotenv
import traceback

# í†µí•©ëœ ê²½ê³  ë° ë¡œê¹… ì„¤ì •
from src.utils.warnings_config import setup_warnings_and_logging
setup_warnings_and_logging()

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

from src.components.context import Context
from src.components.rag_retriever import RAGRetriever
from src.components.code_executor import CodeExecutor
from src.agent import Agent
from src.utils.logger import get_logger
from src.utils.data_profiler import profile_dataframe

app = typer.Typer()

def _update_state_after_prep(df: pd.DataFrame, context: Context, logger, step_info: str) -> pd.DataFrame:
    """[PREP] ë‹¨ê³„ ì„±ê³µ í›„ dfì™€ data_summaryë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í—¬í¼ í•¨ìˆ˜."""
    logger.log_detailed(f"DataFrame state updated after step: {step_info}")
    new_summary = profile_dataframe(df)
    context.set_data_summary(new_summary)
    logger.log_data_summary(new_summary)
    return df

@app.command()
def analyze(
    file_name: str = typer.Option(..., "--file", help="Name of the data file in 'input/data_files/'"),
    request: str = typer.Option(..., "--request", help="Your natural language request for analysis.")
):
    """
    ë°ì´í„° íŒŒì¼ê³¼ ì‚¬ìš©ì ìš”ì²­ì„ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ í†µê³„ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    # ë¡œê±° ì´ˆê¸°í™”
    logger = get_logger()
    
    # --- ì´ˆê¸°í™” ---
    logger.log_system_info("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    
    # .env íŒŒì¼ ë‹¤ì‹œ ë¡œë“œ (ì‹¤ì‹œê°„ ë³€ê²½ì‚¬í•­ ë°˜ì˜)
    load_dotenv(override=True)
    
    # í™˜ê²½ë³€ìˆ˜ ì½ê¸°
    use_rag = os.getenv("USE_RAG", "True").lower() == "true"
    rebuild_vector_store = os.getenv("REBUILD_VECTOR_STORE", "False").lower() == "true"
    
    # ê²½ë¡œ ì„¤ì •
    base_path = Path.cwd()
    input_file_path = base_path / "input" / "data_files" / file_name
    knowledge_base_path = base_path / "resources" / "knowledge_base"

    # vector_store_path ê²½ë¡œ ìƒì„± ë° ì„¤ì •
    vector_store_path = base_path / "resources" / "rag_index"
    vector_store_path.mkdir(parents=True, exist_ok=True)

    # output ê²½ë¡œ ìƒì„± ë° ì„¤ì •
    output_path = base_path / "output"
    output_path.mkdir(parents=True, exist_ok=True)
    report_path = output_path / "reports"
    report_path.mkdir(parents=True, exist_ok=True)
    final_data_path = output_path / "data_files"
    final_data_path.mkdir(parents=True, exist_ok=True)

    # ì»´í¬ë„ŒíŠ¸ ì¸ìŠ¤í„´ìŠ¤í™”
    context = Context()
    agent = Agent()
    executor = CodeExecutor()

    context.set_user_input(file_path=str(input_file_path), request=request)
    logger.log_detailed(f"User Request: {request}")
    logger.log_detailed(f"Data File: {input_file_path}")

    # --- Step 0: ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬ (ë…ë¦½ì  ì‹¤í–‰) ---
    if rebuild_vector_store:
        logger.log_step_start(0, "ë²¡í„° ìŠ¤í† ì–´ ì¬êµ¬ì¶•")
        try:
            # ì„ì‹œ RAGRetriever ì¸ìŠ¤í„´ìŠ¤ë¡œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•ë§Œ ìˆ˜í–‰
            temp_retriever = RAGRetriever(
                knowledge_base_path=knowledge_base_path,
                vector_store_path=vector_store_path,
                rebuild=True
            )
            temp_retriever.load()  # rebuild=Trueì´ë¯€ë¡œ ê¸°ì¡´ ì‚­ì œ í›„ ì¬êµ¬ì¶•
            logger.log_step_success(0, "ë²¡í„° ìŠ¤í† ì–´ ì¬êµ¬ì¶• ì™„ë£Œ")
        except Exception as e:
            logger.log_step_failure(0, f"ë²¡í„° ìŠ¤í† ì–´ ì¬êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")
            logger.log_detailed(f"Vector store rebuild error: {e}", "ERROR")

    # --- Step 1: RAGë¡œ ì»¨í…ìŠ¤íŠ¸ ê°•í™” (ì¡°ê±´ë¶€ ì‹¤í–‰) ---
    if use_rag:
        logger.log_step_start(1, "RAG ì»¨í…ìŠ¤íŠ¸ ê°•í™”")
        
        # ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ ë¨¼ì € í™•ì¸
        vector_store_path_obj = Path(vector_store_path)
        if not (vector_store_path_obj / "docstore.json").exists():
            logger.log_step_failure(1, "ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            print("\nâš ï¸  RAG ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            print("ğŸ“‹ í•´ê²° ë°©ë²•: .env íŒŒì¼ì—ì„œ REBUILD_VECTOR_STORE=Trueë¡œ ì„¤ì •í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            print(f"ğŸ“ ì§€ì‹ ë² ì´ìŠ¤ ê²½ë¡œ: {knowledge_base_path}")
            print(f"ğŸ“ ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ: {vector_store_path}")
            print("\nğŸ’¡ ì§€ì‹ ë² ì´ìŠ¤ì— .md íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¹Œë“œí•´ì£¼ì„¸ìš”.\n")
            # RAG ì—†ì´ ê³„ì† ì§„í–‰
            logger.log_step_success(1, "RAG ì¸ë±ìŠ¤ ì—†ìŒ - RAG ì—†ì´ ë¶„ì„ ì§„í–‰")
        else:
            retriever = RAGRetriever(
                knowledge_base_path=knowledge_base_path, 
                vector_store_path=vector_store_path,
                rebuild=False  # ì¬êµ¬ì¶•ì€ Step 0ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
            )
            try:
                retriever.load()
                
                # RAG ì¿¼ë¦¬ì— íŒŒì¼ ì´ë¦„ê³¼ ì‚¬ìš©ì ìš”ì²­ì„ í•¨ê»˜ ì‚¬ìš©
                rag_query = f"Data file: {file_name}\nUser request: {request}"
                logger.log_detailed(f"RAG Query: {rag_query}")

                rag_context = retriever.retrieve_context(rag_query)
                context.add_rag_result(rag_context)
                logger.log_rag_context(rag_context)
                logger.log_step_success(1, "ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ")
            except Exception as e:
                logger.log_step_failure(1, str(e))
                logger.log_detailed(f"RAG Error: {e}", "ERROR")
    else:
        logger.log_step_start(1, "RAG ê±´ë„ˆë›°ê¸°")
        logger.log_step_success(1, "í™˜ê²½ ì„¤ì •ì— ë”°ë¼ RAG ë‹¨ê³„ ìƒëµ")

    # --- Step 2: ë°ì´í„° ë¡œë”© ë° ì´ˆê¸° íƒìƒ‰ ---
    logger.log_step_start(2, "ë°ì´í„° ë¡œë”© ë° íƒìƒ‰")
    try:
        if input_file_path.suffix == '.csv':
            df = pd.read_csv(input_file_path)
        elif input_file_path.suffix in ['.xlsx', '.xls']:
            df = pd.read_excel(input_file_path)
        elif input_file_path.suffix == '.parquet':
            df = pd.read_parquet(input_file_path)
        else:
            raise ValueError(f"Unsupported file type: {input_file_path.suffix}")

        logger.log_step_success(2, f"ë°ì´í„° ë¡œë”© ì™„ë£Œ ({df.shape[0]}í–‰, {df.shape[1]}ì—´)")
    except FileNotFoundError:
        error_msg = f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file_path}"
        logger.log_step_failure(2, error_msg)
        logger.log_detailed(error_msg, "ERROR")
        sys.exit(1)
    except Exception as e:
        error_msg = f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        logger.log_step_failure(2, error_msg)
        logger.log_detailed(error_msg, "ERROR")
        sys.exit(1)

    # --- Step 3: í†µê³„ ë¶„ì„ ê³„íš ìˆ˜ë¦½ ---
    logger.log_step_start(3, "ë¶„ì„ ê³„íš ìˆ˜ë¦½")
    try:
        # ë°ì´í„° í”„ë¡œíŒŒì¼ë§ ìˆ˜í–‰
        data_summary = profile_dataframe(df)
        context.set_data_summary(data_summary)

        plan = agent.generate_analysis_plan(context)
        context.set_analysis_plan(plan)
        
        logger.log_detailed("Generated Analysis Plan:")
        for i, step in enumerate(plan, 1):
            logger.log_detailed(f"{i}. {step}")
        
        logger.log_step_success(3, f"ë¶„ì„ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ ({len(plan)}ë‹¨ê³„)")
    except Exception as e:
        logger.log_step_failure(3, str(e))
        logger.log_detailed(f"Analysis planning error: {e}", "ERROR")
        sys.exit(1)
    
    # --- Step 4: ê³„íš ê¸°ë°˜ ì‹¤í–‰ ë° ìê°€ ìˆ˜ì • ë£¨í”„ ---
    logger.log_step_start(4, "ë¶„ì„ ê³„íš ì‹¤í–‰")
    try:
        failed_steps = 0
        for i, step in enumerate(context.analysis_plan):
            step_num = i + 1
            logger.log_step_separator()
            logger.log_detailed(f"Executing Step {step_num}: {step}")
            
            rationale, code = agent.generate_code_for_step(context, step)
            logger.log_generated_code(step_num, code, rationale)

            result, status, df_after_execution = executor.run(code, global_vars={'df': df.copy()}) # df.copy()ë¡œ ì•ˆì „ì„± í™•ë³´
            logger.log_execution_result(step_num, result, status != 'ERROR')
            
            context.add_rationale_history(rationale) # Rationaleë„ ê¸°ë¡
            context.add_code_history(code)
            context.add_output_history(result)

            if status == 'SKIPPED':
                context.add_step_to_summary(step, "Skipped")
                continue
            
            if status == 'SUCCESS':
                if step.strip().startswith("[PREP]") and df_after_execution is not None:
                    df = _update_state_after_prep(df_after_execution, context, logger, f"{step_num}")
                context.add_step_to_summary(step, "Success")
            
            elif status == 'ERROR':
                logger.log_detailed(f"Step {step_num} failed, attempting self-correction...")
                
                try:
                    corrected_rationale, corrected_code = agent.self_correct_code(context, step, rationale, code, result)
                    logger.log_detailed(f"Corrected code generated for step {step_num}")
                    logger.log_generated_code(step_num, corrected_code, corrected_rationale, is_corrected=True)
                    
                    result, status, df_after_execution = executor.run(corrected_code, global_vars={'df': df.copy()})
                    logger.log_execution_result(step_num, f"CORRECTED: {result}", status != 'ERROR')
                    
                    context.add_rationale_history(corrected_rationale)
                    context.add_code_history(corrected_code)
                    context.add_output_history(result)

                    if status == 'SUCCESS':
                        if step.strip().startswith("[PREP]") and df_after_execution is not None:
                            df = _update_state_after_prep(df_after_execution, context, logger, f"{step_num} (Corrected)")
                        context.add_step_to_summary(step, "Success (Corrected)")
                    else:
                        raise RuntimeError(f"Self-correction failed. Status: {status}")

                except Exception as e:
                    failed_steps += 1
                    context.add_step_to_summary(step, "Failure (Correction Failed)")
                    logger.log_detailed(f"FATAL: Self-correction failed for step {step_num}. Error: {e}")
        
        if failed_steps == 0:
            logger.log_step_success(4, f"ëª¨ë“  ë¶„ì„ ë‹¨ê³„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ")
        else:
            logger.log_step_success(4, f"ë¶„ì„ ì™„ë£Œ (ì¼ë¶€ ë‹¨ê³„ ì‹¤íŒ¨: {failed_steps}ê°œ)")
            
    except Exception as e:
        # --- í–¥ìƒëœ ì—ëŸ¬ ë¡œê¹… ---
        tb_str = traceback.format_exc()
        logger.log_step_failure(4, f"An unexpected error occurred: {e}")
        logger.log_detailed(f"Analysis execution error: {e}\n{tb_str}", "ERROR")
        logger.log_detailed(f"Context at the time of error: {context.get_full_context()}", "ERROR")
        sys.exit(1)
    
    # --- Step 5: ìµœì¢… ë³´ê³ ì„œ ìƒì„± ---
    logger.log_step_start(5, "ìµœì¢… ë³´ê³ ì„œ ìƒì„±")
    try:
        final_report = agent.generate_final_report(context, final_data_shape=df.shape)
        context.set_final_report(final_report)
        logger.log_step_success(5, "ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        logger.log_step_failure(5, str(e))
        logger.log_detailed(f"Report generation error: {e}", "ERROR")
        final_report = "ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    # --- ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥ ---
    cleaned_report = final_report.strip()
    if cleaned_report.startswith("```markdown"):
        cleaned_report = cleaned_report[11:]
    if cleaned_report.endswith("```"):
        cleaned_report = cleaned_report[:-3]
    
    logger.print_final_report(cleaned_report.strip())
    
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    
    # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
    report_file_name = f"report-{timestamp}.md"
    report_file_path = report_path / report_file_name
    
    try:
        with open(report_file_path, 'w', encoding='utf-8') as f:
            f.write(final_report)
        logger.log_report_saved(str(report_file_path))
    except Exception as e:
        logger.log_detailed(f"Failed to save report: {e}", "ERROR")

    # ìµœì¢… ë°ì´í„°í”„ë ˆì„ ì €ì¥
    final_data_filename = f"final_data-{timestamp}.csv"
    final_data_filepath = final_data_path / final_data_filename
    
    try:
        df.to_csv(final_data_filepath, index=False, encoding='utf-8-sig')
        logger.log_final_data_saved(str(final_data_filepath))
    except Exception as e:
        logger.log_detailed(f"Failed to save final data: {e}", "ERROR")

if __name__ == "__main__":
    app() 